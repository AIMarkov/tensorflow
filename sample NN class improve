import numpy as np
import tensorflow as tf
import math
from matplotlib import pyplot as pl
import time


class NN(object):
    def __init__(self):
        self.X = tf.placeholder(tf.float32, [None, 1])
        self.Y = tf.placeholder(tf.float32, [None, 1])

        self.w1=tf.Variable(tf.random_normal([1,3],stddev=1,seed=1))
        self.bias1=tf.Variable(tf.random_normal([1,3],stddev=1,seed=1))
        self.w2=tf.Variable(tf.random_normal([3,3],stddev=1,seed=1))
        self.bias2=tf.Variable(tf.random_normal([1,3],stddev=1,seed=1))
        self.w3=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))
        self.train_step = tf.train.AdamOptimizer(0.05).minimize(self.loss())
    def forward(self):
        output1=tf.nn.tanh(tf.matmul(self.X,self.w1)+self.bias1)
        output2=tf.nn.tanh(tf.matmul(output1,self.w2)+self.bias2)
        output=tf.matmul(output2,self.w3)
        return output
    def loss(self):
        cross_entropy=tf.reduce_mean(tf.reduce_sum(tf.square(self.Y- self.forward()),
                     reduction_indices=[1]))
        return cross_entropy


nn=NN()

#train_step=tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)

def data(N):
    x=np.random.uniform(0,20,[N,1])
    noise = np.random.normal(0, 0.05, x.shape)
    y=x*2+1+noise
    return  x,y

init=tf.global_variables_initializer()
sess=tf.Session()
sess.run(init)
for i in range(1000):

    x,y=data(100)


    sess.run(nn.train_step,feed_dict={nn.X:x,nn.Y:y})


    print("loss:",sess.run(nn.loss(),feed_dict={nn.X:x,nn.Y:y}))
x,y=data(10)
pl.plot(x,y,'r.')
predict=sess.run(nn.forward(),feed_dict={nn.X:x})
pl.plot(x,predict,'y.')
pl.show()
